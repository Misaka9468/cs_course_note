## Ch1 Operating system interfaces

The shell is an ordinary program that reads commands from the user and executes them.

### 1.1 Processes and memory

- An xv6 process consists of user-space memory (instructions, data, and stack) and per-process state private to the kernel.

![img](https://picx1.zhimg.com/80/v2-b5ea857cbb801a6c77d815b8186e5afa_720w.png?source=d16d100b)



- exit(): 会释放掉进程的资源，包括内存与打开的文件；返回0表示success, 返回1表示failure.
- fork(): 调用对于父进程，返回子进程的pid; 对于子进程，返回0. fork会复制父进程的data和instructions. 包括文件描述符表，对应文件的offset也是相同的. **【相同，但是独立】**
- wait(): 如果父进程没有子进程，wait会直接返回-1. 如果父进程不关心子进程的状态，可以传递(int*)0.
- exec(): argv代表了要传递给可执行文件的参数，argv[0]一般为文件的name, 经常会被忽略.
- **xv6的shell:**
  - 先fork(), 之后wait()等待子进程结束.
  - 子进程负责执行command, 其利用exec()加载elf镜像覆盖memory. 
  - command程序调用exit(), wait()等到后继续执行shell.
  - fork()和exec()分配的memory不够, 需要runtime的memory时, 调用sbrk(n)来获得n字节的内存. 应该分配的是堆内存，类似c语言的malloc().

### 1.2 I/O and File descriptors

- A **file descriptor** is a small integer representing a kernel-managed object that a process may read from or write to.
- 文件描述符对文件、设备、管道进行了一个抽象，将其抽象为一个字节流. 文件描述符本身作为 一个进程专有文件表的下标.
- 特殊的文件描述符: 0,1,2.  
- read(): 会返回已经read的bytes, 如果已经到了文件末尾就会返回0.
- close(): 系统调用会"释放"该文件描述符，使其进入到可用的文件描述符队列(自创名词)中，以供将来的open,pipe以及dup使用. 每次分配最小的、可用的文件描述符.
- **I/O重定向**：例如将input.txt作为输入. 可以close(0), 之后open("/input.txt", O_RDONLY), 最后exec()调用新程序. 这样新程序的代码中使用fd=0的地方就将从input.txt中读.
  - **fork()与exec()分离的好处.  在子进程中I/O重定向，改变文件描述符的含义，并不会影响到父进程.**
- dup(fd) 返回一个新的fd, 这个新文件描述符指向的object与fd的相同.

### 1.3 Pipes

- A pipe is a small kernel buffer exposed to processes as a pair of file descriptors, one for reading and one for writing.
- 在pipe的一端write, 在pipe的另一端可以read到这些data. pipe的存在为进程间的通信提供了一种机制. 在真实的操作系统中，为了让多个程序协同工作，经常需要将一个程序的输出作为另一个程序的输入，此时就需要用到管道机制. 本质是将一个命令的标准输出重定向为另一个命令的标准输入.

```
int p[2];
char *argv[2];
argv[0] = "wc";
argv[1] = 0;
pipe(p);
if(fork() == 0) {
close(0);
dup(p[0]);
close(p[0]);
close(p[1]);
exec("/bin/wc", argv);
} else {
close(p[0]);
write(p[1], "hello world\n", 12);
close(p[1]);
}
```

- p[0]为读端，p[1]为写端.  fork后，子进程会继承父进程的文件描述表，因此父子进程共享pipe这个特殊文件。
- 为什么父子进程在读/写前要close:  close unused end
- 为什么父进程在write后要close(p[1]):  Reader will see EOF.

### 1.4 File system

- 与Linux相同, 如果文件路径前有/代表了绝对路径，否则为被调用进程的当前路径.
- mkdir()创建一个目录, mknod()创建一个指向设备的特殊文件. 当一个进程之后打开该设备文件时，kernel将会用该设备自己实现的read和write代替kernel本身实现的. （记起来了吗？PA2的IOE部分）
- 真正的文件是inode, 其许多的name叫做links. 每一个link包含了一个目录entry, 这个entry包含了filename以及一个inode的reference. 对于每个inode, 它包含了该文件的metadata. (种类, 长度, 在磁盘中的offset, 指向该file的link). 也就是说, inode本身并不会包含文件内容.
- fstat() 的参数为一个fd, 返回该fd指向的inode里的信息，这些信息被存入struct stat中被返回.
- link()和unlink(): 一个会使inode的link增加，一个则会解除. 这两个fd指向同一个inode.
- cd命令内置在shell中, 而不是用户程序(如mkdir, ln, rm). 如果cd是用户程序, 那么在shell中调用cd, 其只会改变fork()后子进程的工作目录，而不会影响父进程即shell本身.

### 1.? C & gdb

- You aren't allowed to use arithmetic on void * pointers officially, but we use GCC, which supports it as an extension to C
- 常见错误，function内返回栈内地址指针.
- **extern:** 
  - 由于编译的过程以源文件为基本单位，引用全局变量、函数前，使用extern声明告诉编译器"肯定有". 具体这些内容的定义存在与否，是链接时的问题。
  - 全局函数默认为extern
  - 头文件中声明的变量为extern, 否则易出现conflict. 主要包含宏定义、函数声明、结构体数据结构定义.
- **static:**
  - 作用于局部变量时，使其生命周期延长到程序结束.
  - 作用于全局变量/函数时，使其只在本文件内可见，避免多文件编译时、因变量函数名相同导致的conflict.
- [GDB](https://www.youtube.com/watch?v=bWH-nL7v5F4)
- [GDB](https://www.youtube.com/watch?v=svG6OPyKsrw)
  -  run
  - break
  - next
  - list
  - print
  - quit
  - up/down
  - display/undisplay
  - backtrace
  - step
  - continue
  - finish
  - watch
  - info/delete
  - whatis
  - target record-full/reverse

## Ch2 Operating system organization

**multiplexing, isolation, and interaction.**

This chapter provides an overview of how operating systems are organized to achieve these three requirements.

### 2.1 Abstracting physical resources

- 将物理硬件资源抽象为对应的服务，防止应用直接访问物理资源，是保证isolation的重要方法。
- Unix的应用只能通过open,close,read,write等文件系统的系统调用来实现对存储资源的访问. 利用文件描述符的抽象来对文件进行管理。
- Unix进程使用exec来build up自己的memory image,而不是直接与物理内存交互。这方便操作系统将进程的内存分配到何处，甚至可以将进程的数据放到disk中(虚存)。

### 2.2 User mode, supervised mode, and system calls

- 操作系统必须保证用户应用无法修改、甚至阅读操作系统的数据结构以及指令。同样地，应用也不应该access其他进程的内存。这样才能保证本应用的bug不会让别的进程或内核挂掉.
- CPU为isolation提供了硬件支持。RISC-V有三个CPU可以执行指令时所处的mode: **machine mode, user mode, and user mode.** 
- 在machine mode下执行的指令拥有全部权限; CPU初始在machine mode下，该模式主要负责计算机的configuration.
- 在supervisor mode下执行的指令可以执行一些特权指令，例：使用、弃用中断，读写包含页表地址信息的寄存器内容。当一个user mode的应用程序想要执行特权指令，CPU会进入supervisor mode并终止该应用程序.
- 只能执行user mode指令的应用程序，被称为运行在user space; 还可以运行特权指令的被称为运行在kernel space. **The software running in kernel space (or in supervisor mode) is called the kernel.**
- 当一个user mode的程序想要调用系统调用时，CPU会提供一个特殊的指令(RISC-V中是ecall)来将CPU从user mode转换到supervisor mode, 并且进入到kernel设置的entry point. 之后CPU会查看system call的传入参数，来决定是否要运行.  当使用系统调用时，实际上会调用ecall并传入对应系统调用号作为参数。
- 在RISC-V中, kernel mode即supervisor mode.

### 2.3 Kernel organization

- **monolithic kernel**
  - Unix属于
  - 整个操作系统的实现都放在内核中，所以所有系统调用都将运行在supervisor mode.
  - 缺点在于，开发者必须小心，因为一个在supervisor mode的bug很有可能让整个系统挂掉.
- **microkernel**
  - Minix属于
  - 减少编写在supervisor mode运行的操作系统代码，让大多数系统代码在user mode运行.
  - 在该组织下，kernel interface 包含一些低级的函数，例如启动程序、传递信息等。OS在user mode下运行的服务被称为servers. microkernel提供了它们之间的信息传递机制.

![img](https://pic1.zhimg.com/80/v2-f43b78aeec56ad910176059db2d01b58_720w.png?source=d16d100b)



### 2.4 Code: xv6 organization

xv6的Kernel文件.  这些文件最后会被编译成一个二进制文件kernel, 运行在qemu上（只需要把qemu看作是一个RISC-V主板即可）

![img](https://pic1.zhimg.com/80/v2-667ec8dc3beeadbdbae670dcbcb1364c_720w.png?source=d16d100b)



 



### 2.5 Process overview

- process即进程，被称作是xv6的isolation的最小单元. kernel实现process的相关策略包括user/supervisor mode flag, address spaces, and time-slicing of threads.
- process的抽象，使得一个程序认为自己拥有独立的内存空间(虚存或address space,由页表实现)，认为自己独享CPU资源(时间分片).
- xv6保留了一个页表，记录了各process的address space.

![img](https://picx1.zhimg.com/80/v2-90351669385edea25722fc079139beaf_720w.png?source=d16d100b)



 

- xv6只用到了地址的38位(64->39->38), 最大的地址为MAXVA = 2^38 − 1 = 0x3fffffffff.  虚存地址从0开始，依次为指令、全局变量、user stack、heap. 在地址空间的顶部有两个page, xv6使用这两个页来实现进入/返回kernel. trampoline page包含了实现进入返回的代码，而trapframe的映射则为用户进程的寄存器状态保存提供作用. 
- kernel/proc.h 定义了进程的结构体, struct proc{}. 

```
struct proc {
  struct spinlock lock;

  // p->lock must be held when using these:
  enum procstate state;        // Process state
  void *chan;                  // If non-zero, sleeping on chan
  int killed;                  // If non-zero, have been killed
  int xstate;                  // Exit status to be returned to parent's wait
  int pid;                     // Process ID

  // wait_lock must be held when using this:
  struct proc *parent;         // Parent process

  // these are private to the process, so p->lock need not be held.
  uint64 kstack;               // Virtual address of kernel stack
  uint64 sz;                   // Size of process memory (bytes)
  pagetable_t pagetable;       // User page table
  struct trapframe *trapframe; // data page for trampoline.S
  struct context context;      // swtch() here to run process
  struct file *ofile[NOFILE];  // Open files
  struct inode *cwd;           // Current directory
  char name[16];               // Process name (debugging)
};
```

- 每个进程都有一个thread, 它可以被悬挂或恢复，进程的切换就需要将对应进程的thread挂起或恢复. 每个进程都有用户栈和内核栈。当进程在用户态时只有用户栈；在内核栈时两个栈中都有内容，但用户栈不经常使用。即使进程的用户栈损坏，也不会影响内核栈的使用。
- RISC-V的ecall提高硬件特权级，将pc指向内核定义的入口点. 入口点的代码将切换到内核栈，并执行相关内核指令完成系统调用。之后使用sret返回到用户态，降低硬件特权级。可以在kernel态等待I/O, 等待后再返回用户态(中断?).

### 2.6 Code: starting xv6, the first process and system call

[3.9 XV6 启动过程 - MIT6.S081](https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/lec03-os-organization-and-system-calls/3.9-xv6-qi-dong-guo-cheng) 

介绍xv6的整个启动流程.

- 当电脑上电时，初始化自己并且运行在ROM中的boot loader. 该loader将会把xv6的kernel加载进内存中物理地址=0x80000000, 低于这个地址的包含了I/O device。在machine mode下，CPU执行kernel/entry.S:7的 *_entry .* RISC-V启动时，不会有页表映射，虚存地址与物理地址相同。
- 在*_entry*的指令建立了一个栈stack0，在kernel/start.c中定义，使得xv6可以运行C程序。在_entry的代码将地址stack0+4096载入栈寄存器sp (栈的长度是4KB, 且是从高向低增长。) 之后_entry会进入到 kernel/start.c 中的start函数. 
- 此时CPU还是处在machine mode. 在start()函数内，会进行一些configuration, 最后asmvolatile("mret")来转移到supervisor mode. mret指令原本是从S-mode回到E-mode, 但是在start.c中，其修改了mstatus使得该寄存器记录的前一个mode被修改为S-mode, 修改寄存器mepc使其指向main函数，关闭在S-mode下的虚拟地址转换，将所有的中断异常都交给S-mode.  在最后调用mret之前，代码调用了一次时钟中断。最后，调用mret就会“回到”S-mode的main处（kernel/main.c: 11）。
- 此时CPU处在S-mode. 在main()中会初始化一些设备和子系统。通过userinit() (kernel/proc.c:233)来产生第一个进程，该函数会执行一个用RISC-V汇编语言写成的程序，会产生xv6的第一个系统调用。initcode.S (user/initcode.S:3) 将系统调用号SYS_EXEC写入寄存器a7, 之后调用ecall返回kernel. kernel执行exec的系统调用，用/init这个程序来覆盖当前进程的内存和寄存器信息。
- 当kernel结束了exec, 它返回到用户空间的/init进程. (user/init.c:15) 该函数会创建一个console设备，开启标准文件描述符，最后在console上运行了shell程序. 

### 2.7  Security Model

It's worthwhile to design safeguards into the kernel against the possibility that it has bugs: assertions, type checking, stack guard pages, etc.

## Ch3 Page tables

页表用来实现地址的转换。

### 3.1 Paging hardware

- xv6运行在Sv39 RISC-V. 也就是说，对于64位的虚拟地址，只会使用低39位. (512GB). 
- 一个RISC-V的页表包含了2^27个page table entries(PTEs), 这与虚拟地址的中间27位是相对应的.  如图所示。每个PTE的低10位为flag位，接下来的44位为物理页号(PPN).  根据该物理页号，最后我们能定位到一个物理页。这个页为2^12即4096字节。
- 页表的高10位暂时不用，但可以用于扩充物理页时，能表示更多的物理页。

![img](https://pic1.zhimg.com/80/v2-749f78eeae7f664403869493c3b5f960_720w.png?source=d16d100b)





- 实际上,RISC-V使用了**三级页表**来处理。
- 这三级页表，每个页表都是一个页（4096字节），含有512个PTE. 
- 图中的二级、三级的页表，按道理应该有 512 、512*512个.
- RISC-V的CPU有一个TLB用于缓存常用的PTE.
- 对于root pagetable page, 我们将其的物理地址存放在寄存器satp中. CPU在访问地址前，都会通过CPU自己的satp寄存器中的页表来进行地址的翻译。不同的CPU都有各自的satp寄存器。

![img](https://pic1.zhimg.com/80/v2-f609cf5ca7612a77c67f11fa16238907_720w.png?source=d16d100b)



- 对于flag:
- **PTE_V:** 有效位，如果没有设置有效，访问时就会抛出页缺失异常。
- **PTE_R/W:** 控制指令是否可以读写该page.
- **PTE_X:** 控制CPU是否可以将该页的内容按指令解释并且执行它们。
- **PTE_U:** 控制CPU是否可以在用户态访问该页。
- 由于页目录存放在物理内存中，所以CPU可以通过访问PTE的虚拟地址，利用标准存储指令来对PTE的内容进行修改。指令只能访问虚拟地址，由paging hardware来将虚拟地址转化为物理地址。

### 3.2 Kernel address space

**本节主要讲解进程的内核地址空间，与之对应的还有用户地址空间。**

- Xv6为每个进程保留了一个页表，描述了该进程的用户地址空间。同时，所有进程还会共享一个内核页表，用于描述内核地址空间。内核可以配置其地址空间的布局，使得其可以通过访问一些约定的虚拟地址来访问物理内存和硬件资源。(kernel/memlayout.h)

![img](https://picx1.zhimg.com/80/v2-0c8076cfa755501ab237a0cb0ac93502_720w.png?source=d16d100b)



 

xv6的内核地址空间布局

- xv6模拟的内存RAM从0x80000000开始，至少在0x88000000终止。一些硬件资源的接口被memory-mapped到0x80000000以下，内核同样可以通过访问这些地址来访问硬件资源。
- 内核使用**直接映射**来访问RAM和采用内存映射的硬件资源寄存器,  即虚拟地址和物理地址相同。kernel本身就存在KERNBASE=0x80000000处。

- **有两种内核虚拟地址不是采用直接映射：**
  - The trampoline page：实际存放code的物理地址，被映射在内核地址空间和用户地址空间的最顶部，同时从图中还可以观察到它还会被直接映射。
  - The kernel stack pages: 每个进程都有自己的内核堆栈，它被映射到较高的位置，因此xv6可以在它下面留下一个未映射的保护页。保护页的PTE无效（即未设置PTE_V），因此如果内核溢出内核堆栈，可能会导致异常，内核将挂掉。如果没有保护页，溢出的堆栈将覆盖其他内核内存，从而导致不正确的操作。从图中可以看出，在内核地址空间的trampoline page下，各进程的内核栈分布情况。每个内核栈大小为PGSIZE, 保护页也是同样的。

- 对于trampoline和内核栈的页，内核在将这些页映射的时候设置为PTE_R and PTE_X, 可读可执行；而对于其他页则设置为PTE_R and PTE_W.

### 3.3 Code: creating an address space

- 在xv6中，每个进程的pagetable地址都在proc结构体内，而内核的pagetable地址则在kernel/vm.c中。

- xv6中大多数有关操作地址空间、页表的代码都在kernel/vm.c中.
- pagetable_t类型，实际上是 uint64*, 其是一个指向RISC-V根页表页的指针. 它既可能是内核的页表，也可能是各进程的页表。以kvm开头的函数处理内核页表相关, uvm类比，其他函数两者都处理。
- **boot流程：**
  - main会调用kvminit(), 在该函数内会调用kvmmake()函数来创建内核的页表。在这个过程中，由于RISC-V还没有启用paging功能，所以采用的都是直接映射。
  - 在kvmmake()函数中，会调用一系列kvmmap()来将内核地址空间中的虚拟地址映射到物理地址。由于我们采用的是直接映射，所以va和pa相同。具体映射了哪些内容，可以见代码以及上图-内核地址空间。最后会调用proc_mapstacks来映射各进程的内核栈。其映射的方式为，对每个进程映射2个页大小，一个用于放栈一个为保护页。
  - 在kvmmap()函数中，其调用了mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm). 其工作流程为，首先使va和pa页对齐，之后从调整后的va为出发点，按页来walk页表找到对应的pte地址。若未找到返回-1，若找到了已有的则panic表示remap, 剩下的情况就修改*pte使其记录该va和pa情况。
  - walk()接收一个va和根页表，根据三级页表结构，查找va对应的pte地址。返回pte地址。 其中有一些宏涉及位操作。
- main()函数内会调用一系列init().  其先调用kvminit()来创建内核的页表；之后再调用kvminithart()来开启页表转换功能。该函数的主要功能是，将内核根页表的物理地址写入到satp寄存器中。
- 每个RISC-V的CPU都有TLB，用于缓存常访问的PTE. 当xv6改变一个页表时，它必须通知CPU来修改TLB中的PTE使其失效。 RISC-V有一个特殊的指令sfence.vma来刷新当前CPU的TLB.  在xv6重新加载satp以及trampoline code转换到用户地址空间之前、转换页表到用户页表后，都要刷新TLB.



###  3.4 Physical memory allocation

内核必须在运行时为页表、用户内存、内核堆栈和管道缓冲区分配和释放物理内存。 Xv6使用内核地址end和PHYSTOP之间的物理内存进行运行时分配。它一次分配和释放整个4096字节的页面。它通过将链表来跟踪哪些页面是空闲的。分配包括从链表中删除页面；释放包括将释放的页面添加到列表中。



### 3.5 Code: Physical memory allocator

本节主要讲述kalloc.c中的相关函数，这些函数完成了物理页的初始化。

xv6将空闲的物理页组织成链表结构 kmem.freelist, 该链表的每个元素为struct run.  该结构体只有一个指针成员，指向下一个run结构体。由此可以得知，该结构体的大小为一个指针的大小即64bit. 这也是为什么我们可以将地址赋给struct run*. 这相当于是，对页物理地址进行了一个结构体封装。

main()函数 (kernel/main.c)中，在创建内核页表kvminit()和开启页转换kvminithart()之前，会调用kinit()函数来分配物理内存页。让我们暂且忘掉lock, 这一系列的逻辑是：

* kinit()调用freerange(), 默认我们的系统有128MB的RAM，将从end(内核物理页分配的起始地址)到PHYSTOP(KERNBASE + 128\*1024\*1024)的所有物理页都free并加入到freelist.
* freerange()中，需要先对起始地址页对齐. 使用PGROUNDUP宏，顾名思义是向上对齐。之后调用kfree来free每一页。
* kfree()中，将当前页memset为1即每个字节为1. 这样做使得使用该页的程序会尽早崩溃（你要是想用，得先从freelist拿下来才可以）. 采用了头插法，类比链式前向星。

 

### 3.6 Process address space

每个进程都有一个独立的页表，当xv6在不同进程切换时，同样会切换页表。

- cpu切换不同的进程时，会向satp中加载各进程对应的root page table(常驻内存，由内核管理)，进程进入到内核态时，使用的是satp里是内核root page table的地址。

进程的地址空间页组织如图所示。注意text为RXU, data stack heap为RWU. 这样做的好处是，当不小心写入到地址0等text所在的位置，会有page fault; 同理，如果pc转移到了data段，执行操作同样会有page fault. 这些都会引起kernel杀掉该进程。

![img](https://pic2.zhimg.com/80/v2-70159605c95908390285174380aab9c5_720w.webp)

user的stack仅有一页，即4096字节。由exec进行初始化，其结构如图所示。从栈顶向下，依次是参数列表String的各子串分隔、这些字符串的地址即argv[n]，然后是参数列表的首地址即char** argv和argc. 这样的结构，像是main(argc,argv)这个函数刚被call时的栈结构。为了防止栈溢出，在栈的下部设置了一个保护页，且权限关掉了PTE_U. 如果用户栈溢出、访问了该页，那么自然因为权限原因抛出了page fault.

**栈溢出：** https://zhuanlan.zhihu.com/p/25816426  . 显然，和函数调用、局部变量有原因。

如果进程想申请更多的用户内存，xv6就会增长该进程的heap. xv6首先用kalloc来分配物理页，之后将指向新分配物理页的PTE添加到该进程的页表中。这些PTE是WRUV的。



### 3.7 Code: sbrk

sbrk这个系统调用，在xv6中由函数growproc(kernel/proc.c:260) 完成。若传递给该函数的n为正，代表堆增长，调用 uvmalloc ， 否则代表堆减小，调用uvmdealloc.

uvmalloc (kernel/vm.c:226) 使用 kalloc 分配物理内存，第二个参数是oldsize, 第三个参数是newsize. 并使用 mappages 将 PTE 添加到用户页表中。 

uvmdealloc 调用 uvmunmap (kernel/vm.c:171)，它使用 walk 来查找 PTE，并使用 kfree 来释放它们引用的物理内存。

一个猜想，malloc和free实际调用的是sbrk()系统调用？
经互联网搜索，一个可能的机制是调用sbrk获取大块内存，然后慢慢分配，每次malloc不一定都会调用sbrk.



### 3.8 Code: exec

exec是用于构建用户地址空间的系统调用，其利用文件系统中存储的某文件binary文件，通过namei (kernel/exec.c) 来打开指定path的文件。对于Xv6，二进制文件的格式为ELF格式。如下图所示。

![img](https://pic2.zhimg.com/80/v2-82eedcbd34c5ff295754595ac3d24b31_720w.webp)

ELF头由struct elfhdr表示，接下来一系列program header描述该程序各section的情况，用struct proghdr表示。



/init是用exec创建的第一个用户程序，其程序部分的Program Header是这样的。v6程序只有一个程序段头。但其他系统可能有单独的指令和数据部分

```
# objdump -p _init

user/_init: file format elf64-littleriscv

Program Header:

LOAD off 0x00000000000000b0 vaddr 0x0000000000000000

paddr 0x0000000000000000 align 2**3

filesz 0x0000000000000840 memsz 0x0000000000000858 flags rwx

STACK off 0x0000000000000000 vaddr 0x0000000000000000

paddr 0x0000000000000000 align 2**4

filesz 0x0000000000000000 memsz 0x0000000000000000 flags rw-
```

为什么filesz会小于memsz呢？忘了.bss段了嘛？因此uvmalloc分配的物理内存是memsz, 但是只读了filesz.

![img](https://pic3.zhimg.com/80/v2-9157f4e7662ca802848b17f5d34f329a_720w.webp)

**exec的流程：**

* 使用ip = namei(path)，打开文件获得inode并赋予struct inode *ip;
* 使用readi读取ELF头，检验ELF_MAGIC格式。
* pagetable = proc_pagetable(p); **使用proc_pagetable来为指定的进程分配一张用户页表**。调用链为proc_pagetable -> uvmcreate -> kalloc。 整个过程就是将kmem的freelist物理内存页中摘下一页，清空为0，并将该页的顶部trampoline和trapframe映射完毕后，把指向该页表的指针赋给pagetable.
* 之后读取program header，按照其提供的vaddr size等信息，为这些需要load的段使用uvmalloc分配物理内存并更新页表的PTE， 然后用loadseg将文件中的内容加载到内存中. 期间要求va是页对齐的，也就对应了用户地址空间图中，text段和data段之间有对齐产生的间隙。在此期间, 地址sz记录了地址空间的当前size.
* 分配两个页。第二个页用作用户栈，前一个页作为保护页(不可访问，否则就会报错，用于检测栈溢出)。sp用于跟踪栈顶（从上往下增长）。
* 填充栈，先填充各**字符串内容**，用ustack[]保存它们在栈中的地址；补一个null ptr代表结束。之后再填充进这些**字符串的地址**。将argv的首地址放入trapframe的a1, argc由exec返回，自然是保存在trapframe的a0 (记得嘛，exec可是系统调用呀). ustack中的前三个条目是假的返回程序计数器、argc和argv的指针.
* 栈填充完毕后，释放掉p的旧页表 proc_freepagetable(oldpagetable, oldsz); ，换上我们的新页表。



我们保证了用户页表和内核页表的隔离性，所以我们在加载文件到内存时，不会因为地址计算溢出等情况，将内容覆盖到内核区域导致shutdown.



### 3.9 Real world

* Xv6认为物理RAM在0x8000000, 这在QEMU模拟的计算机中是正确的。但是实际上，硬件将RAM和不同的设备放在不可预测的物理地址。
* RISC-V对 "超级页 "的支持，在Xv6中没有实现。
* Xv6没有支持为小对象分配内存，每次至少都要是一页（sbrk调用kalloc, kalloc从freelist中取一页）. 这使得Xv6无法支持一些可以动态申请内存的复杂数据结构。

